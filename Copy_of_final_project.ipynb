{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from math import sqrt  # For KNN Euclidean distance\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  \"\"\"Loads the spam data and separates features and labels.\"\"\"\n",
        "  data = pd.read_csv(\"../content/spambase.csv\")\n",
        "  X = data.drop(\"spam\", axis=1)  # Features\n",
        "  y = data[\"spam\"]  # Labels\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "BU4yYeT56oyI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive bayes\n",
        "\n",
        "1. model learning:\n",
        "\n",
        "   Note:\n",
        "\n",
        "   features: remove attributes that is not related to word (the last four attributes)\n",
        "\n",
        "   labels: the last column\n",
        "\n",
        "   count P(c) -> how many samples are positive, and how many are negtive\n",
        "\n",
        "   if freq_word>0, then this word exists. You could use this to calculate P(a|c) -> for each class, what is the prob of each word\n",
        "\n",
        "   remember to use laplace smoothing.\n",
        "\n",
        "2. model evaluation (on val dataset):\n",
        "   \n",
        "   for each new sample, $\\prod{P(a|c)}P(c)$; and find the maximum class\n",
        "   \n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "FXyRfd35yRPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes(X_train, y_train, X_test):\n",
        "  \"\"\"Naive Bayes model implementation.\"\"\"\n",
        "  model = BernoulliNB()  # Use scikit-learn implementation for efficiency\n",
        "  model.fit(X_train, y_train)\n",
        "  predicted_labels = model.predict(X_test)\n",
        "\n",
        "  # Calculate evaluation metrics\n",
        "  accuracy, precision, recall, f1 = calculate_accuracy(y_test, predicted_labels), \\\n",
        "                                    calculate_precision(y_test, predicted_labels), \\\n",
        "                                    calculate_recall(y_test, predicted_labels), \\\n",
        "                                    calculate_f1_score(precision, recall)\n",
        "\n",
        "  return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "zwflzeI860--"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "1. model learning: None\n",
        "\n",
        "2. model evaluation(on val dataset): You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "\n",
        "   ```\n",
        "   Note:\n",
        "   parallel programing\n",
        "   numpy.cos() to calcuate the similarity\n",
        "   ```"
      ],
      "metadata": {
        "id": "5jRvHTlW0DYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(X_train, y_train, X_test, k):\n",
        "  \"\"\"K-Nearest Neighbors model implementation.\"\"\"\n",
        "  predicted_labels = []\n",
        "  for test_instance in X_test.values:\n",
        "    distances = []\n",
        "    for train_instance in X_train.values:\n",
        "      distance = sqrt(sum((a - b) ** 2 for a, b in zip(test_instance[:-1], train_instance[:-1])))\n",
        "      distances.append((distance, train_instance[-1]))\n",
        "\n",
        "    k_nearest_neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
        "    neighbor_labels = [neighbor[1] for neighbor in k_nearest_neighbors]\n",
        "    most_frequent_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "\n",
        "    predicted_labels.append(most_frequent_label)\n",
        "\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "fWF5zQ_X6_WM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR\n",
        "\n",
        "1. model learning: You could use each row(exclude the last column) as the feature of the email. You do not have to recalcuate the freqency.\n",
        "    \n",
        "step 1: add one more column (all value is 1) in X -> X' = np.c_[np.ones((len(X), 1)), X]\n",
        "\n",
        "step 2:vector M = np.random.randn(len(X[0])+1, 1);\n",
        "\n",
        "key formula for step 3 (Note: n is the size of the dataset):\n",
        "\n",
        "1. $pred_y = sigmoid(MX')$\n",
        "\n",
        "2. $loss = -\\sum(y\\cdot log(pred_y)+(1-y)\\cdot log(1-pred_y))/n$\n",
        "\n",
        "3. $gm=x\\cdot (pred_y - y)*2/n$\n",
        "\n",
        "Step 3 example code:\n",
        "   ```\n",
        "   #Step 3: performing gradient descent on whole dataset:\n",
        "   best_model = M\n",
        "   small_loss = 999999\n",
        "   for i in range(epoch):\n",
        "     pred_y = ...\n",
        "     gm = ...\n",
        "     loss = ...\n",
        "     if loss < small_loss:\n",
        "        best_model = M\n",
        "        loss = small_loss\n",
        "     m = m - learning_rate*gm\n",
        "   ```\n",
        "\n",
        "2. model evaluation(on val dataset):\n",
        "  \n",
        "   calculate pred_y, if more than 0.5, then the predicted label is 1."
      ],
      "metadata": {
        "id": "OUzUupva0Fxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression(learning_rate, epochs):\n",
        "  \"\"\"Logistic Regression model implementation.\"\"\"\n",
        "\n",
        "  # Add a column of ones to the feature matrix (X')\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
        "\n",
        "  # Initialize weight vector (M) with random values\n",
        "  m = np.random.randn(len(X_train[0]) + 1, 1)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # Step 1: Calculate predicted probabilities using sigmoid function\n",
        "    pred_y = sigmoid(X_train.dot(m))\n",
        "\n",
        "    # Step 2: Calculate loss (use binary cross-entropy)\n",
        "    loss = -np.sum(y_train * np.log(pred_y) + (1 - y_train) * np.log(1 - pred_y)) / len(y_train)\n",
        "\n",
        "    # Step 3: Calculate gradient (gm)\n",
        "    gm = X_train.T.dot(pred_y - y_train) * 2 / len(y_train)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    m -= learning_rate * gm\n",
        "\n",
        "  # Return the final model weights\n",
        "  return m\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  \"\"\"Sigmoid function implementation.\"\"\"\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def predict(X_test, model_weights):\n",
        "  \"\"\"Predict labels for new data using the trained model.\"\"\"\n",
        "  X_test_with_ones = np.c_[np.ones((len(X_test), 1)), X_test]\n",
        "  predicted_probs = sigmoid(X_test_with_ones.dot(model_weights))\n",
        "  predicted_labels = (predicted_probs > 0.5).astype(int)  # Threshold at 0.5 for spam/not spam\n",
        "  return predicted_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "MHo-Uz_u7QOw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html"
      ],
      "metadata": {
        "id": "mAssSW_I0GvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(true_labels, predicted_labels):\n",
        "  \"\"\"Calculates accuracy metric.\"\"\"\n",
        "  correct_predictions = sum(true_labels == predicted_labels)\n",
        "  accuracy = correct_predictions / len(true_labels)\n",
        "  print(accuracy)\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "def calculate_precision(true_labels, predicted_labels):\n",
        "  \"\"\"Calculates precision metric.\"\"\"\n",
        "  positives = sum(true_labels)\n",
        "  true_positives = sum(\n",
        "      (pred == 1) and (label == 1) for pred, label in zip(predicted_labels, true_labels)\n",
        "  )\n",
        "  precision = true_positives / (positives + 1e-10)  # Avoid division by zero\n",
        "  print(precision)\n",
        "  return precision\n",
        "\n",
        "\n",
        "def calculate_recall(true_labels, predicted_labels):\n",
        "  \"\"\"Calculates recall metric.\"\"\"\n",
        "  positives = sum(true_labels)\n",
        "  true_positives = sum(\n",
        "      (pred == 1) and (label == 1) for pred, label in zip(predicted_labels, true_labels)\n",
        "  )\n",
        "  recall = true_positives / (positives + 1e-10)  # Avoid division by zero\n",
        "  print(recall)\n",
        "  return recall\n",
        "\n",
        "\n",
        "def calculate_f1_score(precision, recall):\n",
        "  \"\"\"Calculates F1 score metric.\"\"\"\n",
        "  f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "  print(f1)\n",
        "  return f1\n",
        "\n",
        "\n",
        "def calculate_auc(true_labels, predicted_probabilities):\n",
        "  \"\"\"Calculates Area Under the ROC Curve (AUC) metric.\"\"\"\n",
        "\n",
        "  # Sort together by predicted probabilities (descending)\n",
        "  sorted_data = sorted(zip(predicted_probabilities, true_labels), reverse=True)\n",
        "  true_labels_sorted = [label for _, label in sorted_data]\n",
        "  predicted_probabilities_sorted = [prob for prob, _ in sorted_data]\n",
        "\n",
        "  # Initialize variables for calculating AUC\n",
        "  last_fpr = -1  # False Positive Rate\n",
        "  last_tpr = 1  # True Positive Rate\n",
        "  auc = 0\n",
        "  n = len(true_labels_sorted)  # Total number of data points\n",
        "\n",
        "  # Iterate through sorted data points\n",
        "  for i in range(n):\n",
        "    # Update False Positive Rate (when label changes from 1 to 0)\n",
        "    if true_labels_sorted[i] == 0 and true_labels_sorted[i-1] == 1:\n",
        "      fpr = i / (n-1)\n",
        "    else:\n",
        "      fpr = last_fpr\n",
        "\n",
        "    # Calculate True Positive Rate for the current data point\n",
        "    tpr = sum(true_labels_sorted[:i+1]) / sum(true_labels)\n",
        "\n",
        "    # Avoid duplicate AUC calculations due to equal probabilities\n",
        "    if fpr != last_fpr:\n",
        "      # Calculate trapezoidal area under the ROC curve for this step\n",
        "      auc += (fpr - last_fpr) * (last_tpr + tpr) / 2\n",
        "      last_fpr = fpr\n",
        "      last_tpr = tpr\n",
        "\n",
        "  # Add the final triangular area\n",
        "  auc += fpr * tpr / 2\n",
        "\n",
        "  print(auc)\n",
        "  return auc\n",
        "\n"
      ],
      "metadata": {
        "id": "sAKzn_707XhU"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}